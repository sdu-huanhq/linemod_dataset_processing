# Introduction
The Linemod dataset is an old object pose estimation dataset,  but until now there was no dataset preprocessing method similar to the coco dataset, so I made a linemod dataset preprocessing method based on pvnet. 
This method can be applied to the preprocessing of pose estimation algorithm based on linemod dataset, and generate coco format annotation files for training, test and validation sets

# Download(Reference PVnet)
1. [Linemod](https://zjueducn-my.sharepoint.com/:u:/g/personal/pengsida_zju_edu_cn/EXK2K0B-QrNPi8MYLDFHdB8BQm9cWTxRGV9dQgauczkVYQ?e=beftUz)
2. [Linemod_orig](https://zjueducn-my.sharepoint.com/:u:/g/personal/pengsida_zju_edu_cn/EaoGIPguY3FAgrFKKhi32fcB_nrMcNRm8jVCZQd7G_-Wbg?e=ig4aHk)
3. [Linemod_occlusion](https://zjueducn-my.sharepoint.com/:u:/g/personal/pengsida_zju_edu_cn/ESXrP0zskd5IvvuvG3TXD-4BMgbDrHZ_bevurBrAcKE5Dg?e=r0EgoA)

```tips: We will only be using some of these three datasets, not all of them, so you only need to focus on the parts we use```

# Introduction to the Dataset
This section explains only the parts that need to be used. The number of objects in the three datasets is not the same, and the specific statistics are as follows(***Glue*** and ***Eggbox*** are symmetric ):

|              | lm-orig |  lm  | lm-o |
| :----------: | :-----: | :--: | :--: |
|     Ape      |    √    |  √   |  √   |
|  Benchvise   |    √    |  √   |  ×   |
|     Bowl     |    √    |  ×   |  ×   |
|     Cam      |    √    |  √   |  ×   |
|     Can      |    √    |  √   |  √   |
|     Cat      |    √    |  √   |  √   |
|     Cup      |    √    |  ×   |  ×   |
|   Driller    |    √    |  √   |  √   |
|     Duck     |    √    |  √   |  √   |
| ***Eggbox*** |    √    |  √   |  √   |
|  ***Glue***  |    √    |  √   |  √   |
| Holepuncher  |    √    |  √   |  √   |
|     Iron     |    √    |  √   |  ×   |
|     Lamp     |    √    |  √   |  ×   |
|    Phone     |    √    |  √   |  ×   |
|     total     |   15    |  13  |  8   |


# Environment
```
numpy
PyOpenGL==3.1.1a1
tqdm
json
pillpw==6.2.2
argparse
```

# Detailed Description
## Linemod
The data we use in linemod has the following parts: ```3D models, RGB images, object standard mask, masking with noise, file names for the training and test sets(txt), bounding box coordinates(2D and 3D) and keypoint coordinates(2D and 3D) of the 3D model```,
If you need model keypoints generated by the fps algorithm, you can read the pvnet source code. 


**Linemod_orig and Linemod_occlusion datasets also have 3D model, but their center coordinates are different from linemod dataset, so we only use the 3D model in linemod**

## Linemod_orig
In Linemod_orig we only use depth information, other information is not used

## Linemod_occlusion


Linemod_occlusion is used for evaluating model. he data we use in linemod has the following parts: ```object pose information, RGB images, depth images```


The images in the Linemod-O dataset are consistent with the benchvise class of the linemod dataset, but the annotation information is different

We strongly encourage you to read the source code for a better understanding




# Citation
> @inproceedings{peng2019pvnet,
  title={PVNet: Pixel-wise Voting Network for 6DoF Pose Estimation},
  author={Peng, Sida and Liu, Yuan and Huang, Qixing and Zhou, Xiaowei and Bao, Hujun},
  booktitle={CVPR},
  year={2019}
}